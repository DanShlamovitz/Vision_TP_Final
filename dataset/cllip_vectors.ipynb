{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRATAR DE GENERAR VECTOR EMBEDDINGS DE LAS IMAGENES USANDO CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from tqdm import tqdm  # For progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "external_drive_path = \"/Volumes/Crucial X9 Pro For Mac/TP_Vision_Final\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing X_train_paths.csv:   0%|          | 3/64801 [00:00<59:49, 18.05image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Image 0 not found in /Volumes/Crucial X9 Pro For Mac/TP_Vision_Final/sample_imgs. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing X_train_paths.csv: 100%|██████████| 64801/64801 [1:48:50<00:00,  9.92image/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors saved to ../data/train_clip_features.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing X_val_paths.csv:   0%|          | 0/7201 [00:00<?, ?image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Image 0 not found in /Volumes/Crucial X9 Pro For Mac/TP_Vision_Final/sample_imgs. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing X_val_paths.csv: 100%|██████████| 7201/7201 [14:27<00:00,  8.30image/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors saved to ../data/val_clip_features.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import clip\n",
    "import pandas as pd  # For handling CSV files\n",
    "\n",
    "# Load the CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Paths\n",
    "data_folder = \"../data\"  \n",
    "image_folder = external_drive_path+\"/sample_imgs\" \n",
    "\n",
    "# CSV file names\n",
    "csv_files = {\n",
    "    \"train\": os.path.join(data_folder, \"X_train_paths.csv\"),\n",
    "    #\"test\": os.path.join(data_folder, \"X_test_paths.csv\"),\n",
    "    \"val\": os.path.join(data_folder, \"X_val_paths.csv\"),\n",
    "}\n",
    "\n",
    "# Function to process images and save features to a CSV file\n",
    "def process_images(csv_file, output_file):\n",
    "    # Load image filenames from the CSV\n",
    "    image_names = pd.read_csv(csv_file, header=None).iloc[:, 0].tolist()\n",
    "\n",
    "    # Initialize a list to store feature vectors\n",
    "    feature_vectors = []\n",
    "\n",
    "    # Process images with a progress bar\n",
    "    for image_name in tqdm(image_names, desc=f\"Processing {os.path.basename(csv_file)}\", unit=\"image\"):\n",
    "        # Construct the full image path\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Warning: Image {image_name} not found in {image_folder}. Skipping.\")\n",
    "            feature_vectors.append([None] * 512)  # Optional: Fill with placeholder for missing images\n",
    "            continue\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "\n",
    "        # Extract features\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image).cpu().numpy().flatten()  # Flatten the tensor\n",
    "\n",
    "        # Add the features to the list\n",
    "        feature_vectors.append(image_features)\n",
    "\n",
    "    # Save the features as a CSV file\n",
    "    pd.DataFrame(feature_vectors).to_csv(output_file, index=False, header=False)\n",
    "    print(f\"Feature vectors saved to {output_file}\")\n",
    "\n",
    "# Process each partition\n",
    "for partition, csv_file in csv_files.items():\n",
    "    output_file = f\"../data/{partition}_clip_features.csv\"\n",
    "    process_images(csv_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
