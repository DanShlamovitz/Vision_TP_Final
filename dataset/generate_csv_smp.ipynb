{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External drive found!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "external_drive_path = \"/Volumes/Crucial X9 Pro For Mac/TP_Vision_Final/train_allmetadata_json\"\n",
    "# Check if the drive is accessible\n",
    "if os.path.exists(external_drive_path):\n",
    "    print(\"External drive found!\")\n",
    "else:\n",
    "    print(\"External drive not found. Check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random_seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE CUANTAS FOTOS AGARRAR\n",
    "n_photos =80000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7f/w8t6fsgd78gfxd_lgh6918b00000gn/T/ipykernel_7234/1164682750.py:1: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  file_paths = pd.read_csv(external_drive_path+'/train_img_filepath.txt', delim_whitespace=True, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7f/w8t6fsgd78gfxd_lgh6918b00000gn/T/ipykernel_7234/1164682750.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  targuets = pd.read_csv(external_drive_path+'/train_label.txt', delim_whitespace=True, header=None)\n"
     ]
    }
   ],
   "source": [
    "file_paths = pd.read_csv(external_drive_path+'/train_img_filepath.txt', delim_whitespace=True, header=None)\n",
    "targuets = pd.read_csv(external_drive_path+'/train_label.txt', delim_whitespace=True, header=None)\n",
    "\n",
    "#50k random number withour repetition \n",
    "\n",
    "random_numbers = range(0, n_photos)\n",
    "print(len(random_numbers))\n",
    "\n",
    "paths = file_paths.iloc[random_numbers].values\n",
    "targuets = targuets.iloc[random_numbers].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7f/w8t6fsgd78gfxd_lgh6918b00000gn/T/ipykernel_7234/2607862423.py:11: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  targuets = [float(targuet) for targuet in targuets]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59@N75 775 11.18\n"
     ]
    }
   ],
   "source": [
    "uids = []\n",
    "pids = []\n",
    "for i in range(len(paths)):\n",
    "    uid = paths[i][0].split('/')[1]\n",
    "    pid = paths[i][0].split('/')[2].split('.')[0]\n",
    "    uids.append(uid)\n",
    "    pids.append(pid)\n",
    "\n",
    "uids = [str(uid) for uid in uids]\n",
    "pids = [str(pid) for pid in pids]\n",
    "targuets = [float(targuet) for targuet in targuets]\n",
    "\n",
    "#create a datgrame from the lists\n",
    "\n",
    "dic = {\n",
    "    'Uid': uids,\n",
    "    'Pid': pids,\n",
    "    'targuet': targuets\n",
    "}\n",
    "df = pd.DataFrame(dic)\n",
    "df = pd.DataFrame(dic)\n",
    "\n",
    "print (dic['Uid'][0], dic['Pid'][0], dic['targuet'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el largo de user_data de es 80000\n",
      "el largo de categorias de es 80000\n",
      "el largo de temporales de es 80000\n"
     ]
    }
   ],
   "source": [
    "#read json file and filter data \n",
    "category = pd.read_json(external_drive_path+'/train_category.json')\n",
    "temporal = pd.read_json(external_drive_path+'/train_temporalspatial_information.json')\n",
    "user_data = pd.read_json(external_drive_path+'/train_user_data.json')\n",
    "\n",
    "\n",
    "\n",
    "category = category[category['Uid'].astype(str).isin(dic['Uid'])]\n",
    "category = category[category['Pid'].astype(str).isin(dic['Pid'])]\n",
    "category['Uid'] = category['Uid'].astype(str)\n",
    "category['Pid'] = category['Pid'].astype(str)\n",
    "\n",
    "temporal = temporal[temporal['Uid'].astype(str).isin(dic['Uid'])]\n",
    "temporal = temporal[temporal['Pid'].astype(str).isin(dic['Pid'])]\n",
    "temporal.drop(['Longitude', 'Geoaccuracy', 'Latitude'], axis=1, inplace=True)\n",
    "temporal['Uid'] = temporal['Uid'].astype(str)\n",
    "temporal['Pid'] = temporal['Pid'].astype(str)\n",
    "\n",
    "user_data = user_data[user_data['Uid'].astype(str).isin(dic['Uid'])]\n",
    "user_data = user_data[user_data['Pid'].astype(str).isin(dic['Pid'])]\n",
    "user_data.drop(['photo_firstdatetaken', 'timezone_id', 'user_description', 'location_description'], axis=1, inplace=True)\n",
    "user_data['Uid'] = user_data['Uid'].astype(str)\n",
    "user_data['Pid'] = user_data['Pid'].astype(str)\n",
    "\n",
    "\n",
    "print(\"el largo de user_data de es\", len(user_data))\n",
    "print(\"el largo de categorias de es\", len(category))\n",
    "print(\"el largo de temporales de es\", len(temporal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data with targuet in order\n",
    "#create dataframe from the lists with the data\n",
    "\n",
    "df = pd.merge(df, category, how='inner', on=['Uid', 'Pid'])\n",
    "df = pd.merge(df, temporal, how='inner', on=['Uid', 'Pid'])\n",
    "df = pd.merge(df, user_data, how='inner', on=['Uid', 'Pid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Uid   Pid  targuet              Category  Concept Subcategory  \\\n",
      "0    59@N75   775    11.18               Fashion     glam     Fashion   \n",
      "1     1@N18  1075    15.15  Travel&Active&Sports     fifa      Soccer   \n",
      "2   351@N64  4890    10.99         Entertainment   cinema      Movies   \n",
      "3     6@N59  6568     8.63  Holiday&Celebrations      old    Birthday   \n",
      "4  1617@N40  7079    11.16                  Food  thirsty      Drinks   \n",
      "\n",
      "     Postdate photo_firstdate  photo_count  ispro timezone_offset  \n",
      "0  1446016778            None       1429.0    1.0            None  \n",
      "1  1454983379            None      43108.0    0.0          -03:00  \n",
      "2  1433118604            None       1035.0    1.0          +01:00  \n",
      "3  1451577600            None      83322.0    1.0          +01:00  \n",
      "4  1425744438            None       5958.0    1.0          -02:00  \n",
      "el largo de todo es de es 80000\n",
      "None\n",
      "Index(['Uid', 'Pid', 'targuet', 'Category', 'Concept', 'Subcategory',\n",
      "       'Postdate', 'photo_firstdate', 'photo_count', 'ispro',\n",
      "       'timezone_offset'],\n",
      "      dtype='object')\n",
      "tiene cantidad de columnas 11\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(print(\"el largo de todo es de es\", len(df)))\n",
    "print(df.columns)\n",
    "print(\"tiene cantidad de columnas\", len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode category\n",
    "one_hot_category = pd.get_dummies(df['Category'])\n",
    "one_hot_subcategory = pd.get_dummies(df['Subcategory'])\n",
    "one_hot_concept = pd.get_dummies(df['Concept'])\n",
    "\n",
    "df.drop(['Category', 'Subcategory', 'Concept'], axis=1, inplace=True)\n",
    "\n",
    "df = pd.concat([df, one_hot_category, one_hot_subcategory, one_hot_concept], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_date_features(df, date_column):\n",
    "    \"\"\"\n",
    "    Realiza one-hot encoding de los meses y días de la semana a partir de un timestamp Unix.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame que contiene la columna de fechas en formato Unix.\n",
    "        date_column (str): Nombre de la columna que contiene las fechas en formato Unix.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame original con las columnas codificadas.\n",
    "    \"\"\"\n",
    "    # Convertir la columna de Unix timestamps a datetime\n",
    "    df['datetime'] = pd.to_datetime(df[date_column], unit='s')\n",
    "    \n",
    "    # Extraer el mes y el día de la semana\n",
    "    df['month'] = df['datetime'].dt.month  # Mes (1 a 12)\n",
    "    df['weekday'] = df['datetime'].dt.dayofweek  # Día de la semana (0=lunes, 6=domingo)\n",
    "    \n",
    "    # Realizar one-hot encoding\n",
    "    one_hot_month = pd.get_dummies(df['month'], prefix='month')\n",
    "    one_hot_weekday = pd.get_dummies(df['weekday'], prefix='weekday')\n",
    "    \n",
    "    # Concatenar las columnas codificadas con el DataFrame original\n",
    "    df = pd.concat([df, one_hot_month, one_hot_weekday], axis=1)\n",
    "    \n",
    "    # Eliminar columnas temporales\n",
    "    df = df.drop(['datetime', 'month', 'weekday'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = one_hot_encode_date_features(df, 'Postdate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Uid   Pid  targuet    Postdate photo_firstdate  photo_count  ispro  \\\n",
      "0    59@N75   775    11.18  1446016778            None       1429.0    1.0   \n",
      "1     1@N18  1075    15.15  1454983379            None      43108.0    0.0   \n",
      "2   351@N64  4890    10.99  1433118604            None       1035.0    1.0   \n",
      "3     6@N59  6568     8.63  1451577600            None      83322.0    1.0   \n",
      "4  1617@N40  7079    11.16  1425744438            None       5958.0    1.0   \n",
      "\n",
      "  timezone_offset  Animal  Electronics  ...  month_10  month_11  month_12  \\\n",
      "0            None   False        False  ...      True     False     False   \n",
      "1          -03:00   False        False  ...     False     False     False   \n",
      "2          +01:00   False        False  ...     False     False     False   \n",
      "3          +01:00   False        False  ...     False     False      True   \n",
      "4          -02:00   False        False  ...     False     False     False   \n",
      "\n",
      "   weekday_0  weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  weekday_6  \n",
      "0      False      False       True      False      False      False      False  \n",
      "1      False       True      False      False      False      False      False  \n",
      "2       True      False      False      False      False      False      False  \n",
      "3      False      False      False       True      False      False      False  \n",
      "4      False      False      False      False      False       True      False  \n",
      "\n",
      "[5 rows x 483 columns]\n",
      "el largo de todo es de es 80000\n",
      "None\n",
      "Index(['Uid', 'Pid', 'targuet', 'Postdate', 'photo_firstdate', 'photo_count',\n",
      "       'ispro', 'timezone_offset', 'Animal', 'Electronics',\n",
      "       ...\n",
      "       'month_10', 'month_11', 'month_12', 'weekday_0', 'weekday_1',\n",
      "       'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6'],\n",
      "      dtype='object', length=483)\n",
      "tiene cantidad de columnas 483\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(print(\"el largo de todo es de es\", len(df)))\n",
    "print(df.columns)\n",
    "print(\"tiene cantidad de columnas\", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data as csv\n",
    "df.to_csv('../data/metadata/all_metadata.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
