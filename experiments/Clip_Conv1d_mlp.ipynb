{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA available: False\n",
      "CUDA version: None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import clip\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv1d(input_dim=512, kernel_size=3, padding=1, stride=1, num_layers=3, channels_per_layer=[256, 128, 64]):\n",
    "    print(f\"Input size for Conv1D: {input_dim}\")\n",
    "    if len(channels_per_layer) != num_layers:\n",
    "        raise ValueError(\"The number of channels per layer must match the number of layers\")\n",
    "    layers = []\n",
    "\n",
    "    layers.append(nn.Conv1d(in_channels=input_dim, out_channels=channels_per_layer[0], kernel_size=kernel_size, padding=padding, stride=stride))\n",
    "    layers.append(nn.BatchNorm1d(channels_per_layer[0]))\n",
    "    layers.append(nn.ReLU())\n",
    "\n",
    "    in_channels = channels_per_layer[0]\n",
    "    for out_channels in channels_per_layer[1:]:\n",
    "        layers.append(nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding, stride=stride))\n",
    "        layers.append(nn.BatchNorm1d(out_channels))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "\n",
    "    model = nn.Sequential(*layers)\n",
    "    print(f\"Output size for Conv1D: {channels_per_layer[-1]}\")  \n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_mlp(input_dim=532, num_layers=3, hidden_per_layer=[256, 128, 64], output_dim=1):\n",
    "    print(f\"Input size for MLP: {input_dim}\")\n",
    "    if len(hidden_per_layer) != num_layers:\n",
    "        raise ValueError(\"The number of hidden units per layer must match the number of layers\")\n",
    "    \n",
    "    layers = []\n",
    "    in_features = input_dim\n",
    "    for out_features in hidden_per_layer:\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())  # Usamos ReLU como función de activación en las capas ocultas\n",
    "        in_features = out_features\n",
    "    \n",
    "    layers.append(nn.Linear(in_features, output_dim))    \n",
    "    model = nn.Sequential(*layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, input_dim_images=512, input_dim_tabular=30, kernel_size_images=3, kernel_size_tabular=3, padding=1, stride=1, num_layers_1=3, num_layers_2=3, channels_per_layer_1=[32, 20, 10], channels_per_layer_2=[32, 20, 10], mlp_hidden=[8, 5, 3]):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        mlp_input_dim = channels_per_layer_1[-1] + channels_per_layer_2[-1]\n",
    "        self.conv1 = create_conv1d(input_dim=input_dim_images, kernel_size=kernel_size_images, padding=padding, stride=stride, num_layers=num_layers_1, channels_per_layer=channels_per_layer_1)\n",
    "        self.conv2 = create_conv1d(input_dim=input_dim_tabular, kernel_size=kernel_size_tabular, padding=padding, stride=stride, num_layers=num_layers_2, channels_per_layer=channels_per_layer_2)\n",
    "        self.mlp = create_mlp(input_dim=mlp_input_dim, num_layers=len(mlp_hidden), hidden_per_layer=mlp_hidden)\n",
    "\n",
    "    def forward(self, X_images, X_tabular):\n",
    "        # Pasar los datos por ambas ramas convolucionales\n",
    "        x1 = self.conv1(X_images)\n",
    "        x2 = self.conv2(X_tabular)\n",
    "        # Concatenar los resultados\n",
    "        x1 = x1.view(x1.size(0), -1)  # Aplanar\n",
    "        x2 = x2.view(x2.size(0), -1)  # Aplanar\n",
    "\n",
    "        x_combined = torch.cat((x1, x2), dim=1)  # Concatenación\n",
    "        output = self.mlp(x_combined)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def train_model(self, X_images_train, X_tabular_train, Y_train, epochs=10, batch_size=32, learning_rate=0.001, loss_fn=F.mse_loss):\n",
    "        # Initialize optimizer\n",
    "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Convert to TensorDataset and DataLoader\n",
    "        train_dataset = torch.utils.data.TensorDataset(X_images_train, X_tabular_train, Y_train)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "                # Check for NaN or Inf values in the inputs\n",
    "                if torch.any(torch.isnan(X_images)) or torch.any(torch.isnan(X_tabular)) or torch.any(torch.isnan(y)):\n",
    "                    print(f\"NaN detected in inputs at batch {batch_idx}\")\n",
    "                    continue\n",
    "\n",
    "                if torch.any(torch.isinf(X_images)) or torch.any(torch.isinf(X_tabular)) or torch.any(torch.isinf(y)):\n",
    "                    print(f\"Inf detected in inputs at batch {batch_idx}\")\n",
    "                    continue\n",
    "\n",
    "                outputs = self(X_images, X_tabular)\n",
    "                \n",
    "                # Check for NaN or Inf in the model's outputs\n",
    "                if torch.any(torch.isnan(outputs)) or torch.any(torch.isinf(outputs)):\n",
    "                    print(f\"NaN/Inf detected in model output at batch {batch_idx}\")\n",
    "                    continue\n",
    "\n",
    "                loss = loss_fn(outputs, y)\n",
    "                print(f\"Loss at batch {batch_idx}: {loss.item()}\")\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tabular_train = pd.read_csv(\"../data/preprocessed/train/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../data/preprocessed/train/Y_train.csv\")\n",
    "X_images_train = pkl.load(open(\"../data/preprocessed/train/train_clip_vectors.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DatePosted</th>\n",
       "      <th>DateTaken</th>\n",
       "      <th>DateCrawl</th>\n",
       "      <th>NumSets</th>\n",
       "      <th>NumGroups</th>\n",
       "      <th>AvgGroupsMemb</th>\n",
       "      <th>AvgGroupPhotos</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>HasStats</th>\n",
       "      <th>Contacts</th>\n",
       "      <th>PhotoCount</th>\n",
       "      <th>MeanViews</th>\n",
       "      <th>GroupsCount</th>\n",
       "      <th>GroupsAvgMembers</th>\n",
       "      <th>GroupsAvgPictures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1507147765</td>\n",
       "      <td>1507147765</td>\n",
       "      <td>1507155322</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>7006</td>\n",
       "      <td>21.114331</td>\n",
       "      <td>153</td>\n",
       "      <td>17954.915033</td>\n",
       "      <td>328481.45098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1507147800</td>\n",
       "      <td>1507147800</td>\n",
       "      <td>1507151128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>565</td>\n",
       "      <td>65.538053</td>\n",
       "      <td>4</td>\n",
       "      <td>19875.750000</td>\n",
       "      <td>1215.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1507147801</td>\n",
       "      <td>1507147801</td>\n",
       "      <td>1507149986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>562</td>\n",
       "      <td>70.215302</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1507147811</td>\n",
       "      <td>1507147811</td>\n",
       "      <td>1507154551</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>485</td>\n",
       "      <td>397</td>\n",
       "      <td>162.307305</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1507147820</td>\n",
       "      <td>1507147820</td>\n",
       "      <td>1507153563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19380</td>\n",
       "      <td>265.643400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DatePosted   DateTaken   DateCrawl  NumSets  NumGroups  AvgGroupsMemb  \\\n",
       "0  1507147765  1507147765  1507155322        1          0            0.0   \n",
       "1  1507147800  1507147800  1507151128        1          0            0.0   \n",
       "2  1507147801  1507147801  1507149986        0          0            0.0   \n",
       "3  1507147811  1507147811  1507154551        1          0            0.0   \n",
       "4  1507147820  1507147820  1507153563        0          0            0.0   \n",
       "\n",
       "   AvgGroupPhotos  Tags  Latitude  Longitude  HasStats  Contacts  PhotoCount  \\\n",
       "0             0.0     1       NaN        NaN         1       148        7006   \n",
       "1             0.0     1       NaN        NaN         0        55         565   \n",
       "2             0.0     1       NaN        NaN         0         5         562   \n",
       "3             0.0     1       NaN        NaN         0       485         397   \n",
       "4             0.0     1       NaN        NaN         0         1       19380   \n",
       "\n",
       "    MeanViews  GroupsCount  GroupsAvgMembers  GroupsAvgPictures  \n",
       "0   21.114331          153      17954.915033       328481.45098  \n",
       "1   65.538053            4      19875.750000         1215.50000  \n",
       "2   70.215302            0          0.000000            0.00000  \n",
       "3  162.307305            0          0.000000            0.00000  \n",
       "4  265.643400            0          0.000000            0.00000  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tabular_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day30\n",
       "0   18.0\n",
       "1    9.0\n",
       "2   11.0\n",
       "3  121.0\n",
       "4  228.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn df into torch tensor\n",
    "X_tabular_train = torch.tensor(X_tabular_train.values).float().unsqueeze(2) \n",
    "X_images_train = torch.cat(X_images_train, dim=0).unsqueeze(2) \n",
    "y_train = torch.tensor(y_train.values).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tabular_shape:  torch.Size([18303, 17, 1])\n",
      "X_images_shape:  torch.Size([18303, 512, 1])\n",
      "y_shape:  torch.Size([18303, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"X_tabular_shape: \", X_tabular_train.shape)\n",
    "print(\"X_images_shape: \", X_images_train.shape)\n",
    "print(\"y_shape: \", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size for Conv1D: 512\n",
      "Output size for Conv1D: 10\n",
      "Input size for Conv1D: 17\n",
      "Output size for Conv1D: 10\n",
      "Input size for MLP: 20\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m CombinedModel(input_dim_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, input_dim_tabular\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m17\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_images_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_tabular_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[113], line 32\u001b[0m, in \u001b[0;36mCombinedModel.train_model\u001b[0;34m(self, X_images_train, X_tabular_train, Y_train, epochs, batch_size, learning_rate, loss_fn)\u001b[0m\n\u001b[1;32m     28\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;66;03m# Check for NaN or Inf values in the inputs\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39misnan(\u001b[43mX_images\u001b[49m)) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39misnan(X_tabular)) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39misnan(y)):\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN detected in inputs at batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_images' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model = CombinedModel(input_dim_images=512, input_dim_tabular=17)\n",
    "model.train_model(X_images_train, X_tabular_train, y_train, epochs=10, batch_size=32, learning_rate=0.001, loss_fn=F.mse_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
