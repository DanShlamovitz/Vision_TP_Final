{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm as tqdm\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomResNet50Regression(nn.Module):\n",
    "    def __init__(self, output_size=1, fine_tune=True):\n",
    "        super(CustomResNet50Regression, self).__init__()\n",
    "        # Cargar la ResNet50 preentrenada\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "        # Reemplazar la última capa para regresión\n",
    "        self.resnet50.fc = nn.Linear(self.resnet50.fc.in_features, output_size)\n",
    "        # Congelar capas convolucionales si no se desea fine-tuning\n",
    "        if not fine_tune:\n",
    "            for param in self.resnet50.parameters():\n",
    "                param.requires_grad = False\n",
    "            # Solo las capas de la fc estarán entrenables\n",
    "            for param in self.resnet50.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "\n",
    "    def train_model(self, train_loader, val_loader, epochs, learning_rate, fine_tune=True, device='cuda'):\n",
    "        self.to(device)\n",
    "        criterion = nn.MSELoss()  # Función de pérdida para regresión\n",
    "        optimizer = optim.Adam(self.parameters() if fine_tune else self.resnet50.fc.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Entrenamiento\n",
    "            self.train()\n",
    "            train_loss = 0.0\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validación\n",
    "            self.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = self(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18303/18303 [02:57<00:00, 103.09it/s]\n",
      "100%|██████████| 2034/2034 [00:28<00:00, 72.54it/s]\n"
     ]
    }
   ],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Redimensionar la imagen\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convertir imágenes en escala de grises a 3 canales (RGB)\n",
    "    transforms.ToTensor(),  # Convertir la imagen a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalización\n",
    "])\n",
    "y_train = torch.tensor(pd.read_csv('../data/preprocessed/train/Y_train.csv')['Day30'].values, dtype=torch.float32)\n",
    "y_test = torch.tensor(pd.read_csv('../data/preprocessed/test/Y_test.csv')['Day30'].values, dtype=torch.float32)\n",
    "\n",
    "train_images = []\n",
    "test_images = []\n",
    "\n",
    "train_img_dir = '../data/preprocessed/train/train_imgs'\n",
    "train_img_names = os.listdir(train_img_dir)\n",
    "\n",
    "for img_name in tqdm(train_img_names):\n",
    "    img_path = os.path.join(train_img_dir, img_name)\n",
    "    image = Image.open(img_path)\n",
    "    image = data_transforms(image)  # Aplicar las transformaciones\n",
    "    train_images.append(image)\n",
    "train_images_tensor = torch.stack(train_images)\n",
    "\n",
    "test_img_dir = '../data/preprocessed/test/test_imgs'\n",
    "test_img_names = os.listdir(test_img_dir)\n",
    "\n",
    "for img_name in tqdm(test_img_names):\n",
    "    img_path = os.path.join(test_img_dir, img_name)\n",
    "    image = Image.open(img_path)\n",
    "    image = data_transforms(image)  # Aplicar las transformaciones\n",
    "    test_images.append(image)\n",
    "test_images_tensor = torch.stack(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dan/miniconda3/envs/ML/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/dan/miniconda3/envs/ML/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = CustomResNet50Regression(output_size=1, fine_tune=True)\n",
    "train_dataset = torch.utils.data.TensorDataset(train_images_tensor, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_images_tensor, y_test)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    " \n",
    "model.train_model(train_loader, test_loader, epochs=10, learning_rate=0.001, fine_tune=False, device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
