{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm as tqdm\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Regresion:\n",
    "    def __init__(self, batch_size=32, learning_rate=1e-4, epochs=10, device=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.modelo = self.get_model().to(self.device)\n",
    "\n",
    "        self.criterion = nn.MSELoss()  # Para regresión, usamos error cuadrático medio\n",
    "        self.optimizer = optim.Adam(self.modelo.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def get_model(self):\n",
    "        modelo_resnet = models.resnet50(pretrained=True)\n",
    "        for param in modelo_resnet.parameters():\n",
    "            param.requires_grad = False  # Congelar todas las capas\n",
    "            \n",
    "        num_ftrs = modelo_resnet.fc.in_features\n",
    "        modelo_resnet.fc = nn.Linear(num_ftrs, 1)  # Cambiar la capa final para regresión\n",
    "        return modelo_resnet\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.modelo.train()\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            running_loss = 0.0\n",
    "            for i in range(0, len(X_train), self.batch_size):\n",
    "                batch_inputs = X_train[i:i+self.batch_size]\n",
    "                batch_labels = y_train[i:i+self.batch_size]\n",
    "                inputs = torch.stack(batch_inputs).to(self.device)\n",
    "                labels = torch.tensor(batch_labels, dtype=torch.float32).to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.modelo(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs.squeeze(), labels)  # Squeeze para eliminar la dimensión extra\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "\n",
    "            epoch_loss = running_loss / len(X_train)\n",
    "            print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    def save_model(self, ruta):\n",
    "        torch.save(self.modelo.state_dict(), ruta)\n",
    "        print(f\"Modelo guardado en {ruta}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        self.modelo.eval()  # Poner el modelo en modo de evaluación\n",
    "        predicciones = []\n",
    "\n",
    "        for img_tensor in X_test:\n",
    "            img_tensor = img_tensor.unsqueeze(0).to(self.device)  # Agregar una dimensión para batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = self.modelo(img_tensor)\n",
    "                predicciones.append(output.item())\n",
    "\n",
    "        return predicciones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "# Cargar los datos\n",
    "lista_paths_train = pd.read_csv(\"../X_test_paths.csv\").iloc[:, 0].tolist()\n",
    "etiquetas_train = pd.read_csv(\"../y_test.csv\").iloc[:, 0].tolist() \n",
    "\n",
    " # Cargar las imágenes y aplicar las transformaciones\n",
    "X_train = []\n",
    "for path in lista_paths_train:\n",
    "    path = f\"../imgs/{path}\"\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    img_tensor = transform(img)  # Aplicar las transformaciones\n",
    "    X_train.append(img_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voy a entrenar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dan/miniconda3/envs/ML/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/dan/miniconda3/envs/ML/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pasito\n",
      "hola tensor(55.1939, grad_fn=<MseLossBackward0>)\n",
      "pasito\n"
     ]
    }
   ],
   "source": [
    "modelo = ResNet50Regresion(batch_size=3000, epochs=2, learning_rate=1e-4)\n",
    "\n",
    "    # Entrenar el modelo\n",
    "modelo.fit(X_train, etiquetas_train)  # Pasar las imágenes procesadas y las etiquetas\n",
    "\n",
    "# Guardar el modelo\n",
    "modelo.save_model(\"../modelo_resnet50.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
